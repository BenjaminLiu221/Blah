{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the time of ecommerce and online shopping with companies or brands like Nike, Adidas, H&M started building their online presence to cater to customers to shop online. Shopping online for clothing and footwear was becoming more common. \n",
    "\n",
    "Reddit's [Frugal Male Fashion subreddit](https://www.reddit.com/r/frugalmalefashion) is where users share information about coupons, discounts and sales on a variety of brands and stores. Popular posts are upvoted and headlined at the top, but users can also filter for most recent or most relevant searches. The continuous postings can streamline viewers to the forum increasing advertisement revenue. \n",
    "\n",
    "In order to maintain a clean environment and better retain constant users online, only content that is relevant to the community will be allowed to be posted and irrelevant content will be removed. An example of irrelevant content is a user posting present or future acquisition of hype sneakers. We will be retrieving posts from Reddit's [Sneakers subreddit](https://www.reddit.com/r/sneakers) where users share their present or future acquisitions of hype sneakerwear.\n",
    "\n",
    "Posts from `r/frugalmalefashion` will be Class 1 and posts from `r/sneakers` will be Class 0. We will be analyzing the documents to build a model that accurately classifies a post as from Class 1 but also outputs interpretable results for downstream data visualization and businesss applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /Applications/anaconda3/lib/python3.6/site-packages (2.7.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import regex as re\n",
    "import requests\n",
    "import psycopg2 as pg2\n",
    "from datetime import datetime, timedelta\n",
    "from psycopg2.extras import RealDictCursor, Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../sql_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configure Postgres SQL Server with Docker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to programmatically connect to and insert data into database:\n",
    "- **con_cur_to_db**: returns both a connection and a cursor object for database\n",
    "- **execute_query**: executes query directly to database, without having to create a cursor and connection each time\n",
    "- **insert_entry_json**: inserts data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection\n",
    "\n",
    "def insert_entry_json(data, tablename=None):\n",
    "    con, cur = con_cur_to_db()\n",
    "    for x in data:\n",
    "        cur.execute(f'INSERT INTO {tablename} (data) VALUES ({Json(x)});')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create table raw_posts to save our collected data into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''CREATE TABLE raw_posts\n",
    "(id SERIAL,\n",
    "data JSONB);'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = '''DROP TABLE raw_posts'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(query, command=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collect Posts from Subreddits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function using Reddit's pushshiftAPI that retrieves posts and saves them into a SQL Database:\n",
    "- `subreddit`: domain of reddit\n",
    "- `limit`: cap on how much data to retrieve\n",
    "- `after`: begin date\n",
    "- `before`: end date\n",
    "- `sql_db`: SQL Database\n",
    "- `time sleep`: rest latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamComments(subreddit, sql_db, limit=1000, before=None, after=None):\n",
    "    url = f'https://apiv2.pushshift.io/reddit/submission/search/'\n",
    "    last_comment = before\n",
    "    \n",
    "    num_comments = 0\n",
    "    while num_comments < limit:\n",
    "            params = {\n",
    "              'subreddit':subreddit,\n",
    "              'sort':'desc',\n",
    "              'size':1000,\n",
    "              'before':last_comment-1,\n",
    "              'after':after,\n",
    "             }\n",
    "                \n",
    "            response = requests.get(url, params=params)\n",
    "            posts = response.json()['data']\n",
    "            \n",
    "            if len(posts) == 0:\n",
    "                last_comment = last_comment\n",
    "            else:\n",
    "                last_comment = posts[-1]['created_utc']\n",
    "                insert_entry_json(data = posts, \n",
    "                          tablename = sql_db)\n",
    "                timestamp = posts[-1]['created_utc']\n",
    "                time.sleep(1)\n",
    "                num_comments+=len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Frugal Male Fashion Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a loop such to send a request to the pushshiftAPI to retrieve the most recent posts from `r/frugalmalefashion` with a limit of 50,000 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "end = round(time.time())\n",
    "streamComments(subreddit='frugalmalefashion',\n",
    "             limit=50000,\n",
    "             sql_db='raw_posts',\n",
    "             before=end)\n",
    "    \n",
    "end = time.time()\n",
    "print(str(timedelta(seconds=(end-start))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sneakers Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a loop such to send a request to the pushshiftAPI to retrieve the most recent posts from `r/sneakers` with a limit of 50,000 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "end = round(time.time())\n",
    "streamComments(subreddit='sneakers',\n",
    "             limit=50000,\n",
    "             sql_db='raw_posts',\n",
    "             before=end)\n",
    "    \n",
    "end = time.time()\n",
    "print(str(timedelta(seconds=(end-start))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieve Data from Postgres SQL Database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../image/keys_of_interest.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys of interest:\n",
    "- `title`: title text of post\n",
    "- `selftext`: body text of post\n",
    "- `subreddit`: reddit domain\n",
    "- `created_utc`: UNIX timestamp as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'title'\n",
    "FROM raw_posts;\n",
    "\"\"\"\n",
    "title = execute_query(query, dict_cur=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [i['?column?'] for i in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'selftext'\n",
    "FROM raw_posts;\n",
    "\"\"\"\n",
    "selftext = execute_query(query, dict_cur=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selftext = ['' if i['?column?'] == None else i['?column?'] for i in selftext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'subreddit'\n",
    "FROM raw_posts;\n",
    "\"\"\"\n",
    "subreddit = execute_query(query, dict_cur=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = [i['?column?'] for i in subreddit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'created_utc'\n",
    "FROM raw_posts;\n",
    "\"\"\"\n",
    "created_utc = execute_query(query, dict_cur=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [datetime.utcfromtimestamp(int(i['?column?'])).year for i in created_utc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'title':title,\n",
    "                   'selftext':selftext,\n",
    "                   'subreddit':subreddit,\n",
    "                   'year':year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to find the best offers and deals on lapda...</td>\n",
       "      <td>DEALS &amp;amp; SALES</td>\n",
       "      <td>frugalmalefashion</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Columbia Fleece, various colors and sizes, $17...</td>\n",
       "      <td></td>\n",
       "      <td>frugalmalefashion</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pacsun- Vans Old Skool $26.99, sizes 9-13, fre...</td>\n",
       "      <td>https://www.pacsun.com/vans/old-skool-green-wh...</td>\n",
       "      <td>frugalmalefashion</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Massive Toad&amp;amp;Co Sale (Some items 90% off)</td>\n",
       "      <td>Noooo idea if this was an error or not, but ju...</td>\n",
       "      <td>frugalmalefashion</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHUP socks for $10 with code 30MORE</td>\n",
       "      <td></td>\n",
       "      <td>frugalmalefashion</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to find the best offers and deals on lapda...   \n",
       "1  Columbia Fleece, various colors and sizes, $17...   \n",
       "2  Pacsun- Vans Old Skool $26.99, sizes 9-13, fre...   \n",
       "3      Massive Toad&amp;Co Sale (Some items 90% off)   \n",
       "4                CHUP socks for $10 with code 30MORE   \n",
       "\n",
       "                                            selftext          subreddit  year  \n",
       "0                                  DEALS &amp; SALES  frugalmalefashion  2019  \n",
       "1                                                     frugalmalefashion  2019  \n",
       "2  https://www.pacsun.com/vans/old-skool-green-wh...  frugalmalefashion  2019  \n",
       "3  Noooo idea if this was an error or not, but ju...  frugalmalefashion  2019  \n",
       "4                                                     frugalmalefashion  2018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Remove Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "selftext     0\n",
       "subreddit    0\n",
       "year         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove the following posts which indicate:\n",
    "- **[removed]**: the post was irrelevant to the community or inappropriate and was removed by subreddit.\n",
    "- **[deleted]**: the user removed own post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['selftext'] != '[removed]') & \n",
    "              (df['title'] != '[removed]') &\n",
    "              (df['selftext'] != '[deleted]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Combined Title and Selftext**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combined `title` and `selftext` into `text` and drop the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['title'] + ' ' + df['selftext']\n",
    "df.drop(['title','selftext'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observe Time Range of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    34747\n",
       "2019    22953\n",
       "2015    10020\n",
       "2014     6571\n",
       "2017     5903\n",
       "2016     4530\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Define Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will classify posts from `frugalmalefashion` to be `Class 1` representing relevant content and posts from `sneakers` to be `Class 0` representing irrelevant content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = [1 if i=='frugalmalefashion' else 0 for i in df['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45910\n",
       "1    38814\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.541877\n",
       "1    0.458123\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight imbalance of classes with `Class 0` being the majority class of 54.19% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing on Text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use regular expressions to remove words, symbols, characters that won't contribute real signal to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subreddit Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: re.sub('\\s[\\/]?r\\/[^\\s+]+', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: re.sub('[0-9]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: re.sub('[(){}[\\]`~!@#$%^&*-_=+;,.<>?]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: x.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: x.replace('\\r', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: x.replace('\\t', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip leading and ending whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip duplicate whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save out Dataframe as csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
